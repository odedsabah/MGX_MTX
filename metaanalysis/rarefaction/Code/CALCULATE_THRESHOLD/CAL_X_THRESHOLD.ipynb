{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_mp4_files = os.path.expanduser(\"~/out_stats_fastq/\")\n",
    "csv_files = glob.glob(os.path.join(path_mp4_files, '**', '*.csv'), recursive=True)\n",
    "\n",
    "df_dict_thresh = {}\n",
    "df_dict_split = {}\n",
    "\n",
    "for file in csv_files:\n",
    "    id_file = file.split(\"_\")[-3]\n",
    "    thresh_file = file.split(\"_\")[-1].rstrip('.csv')\n",
    "    process_type = file.split(\"_\")[-2]\n",
    "\n",
    "    # Read csv file into dataframe\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Add id_file as a column in the dataframe\n",
    "    df['id_file'] = id_file\n",
    "    df['thresh_file'] = thresh_file\n",
    "    df[\"process_type\"] = process_type\n",
    "\n",
    "    # Change the index for dataframes where process_type == 'trash'\n",
    "    if process_type == 'trash' and \"index\" in df.columns:\n",
    "        df[\"index\"] = [index.split(\".\")[1] for index in df[\"index\"]]\n",
    "\n",
    "    # Set id_file as the index of the dataframe\n",
    "    df.set_index('id_file', inplace=True)\n",
    "\n",
    "    # Create a key for the dictionary\n",
    "    key_thresh = (id_file, thresh_file, process_type)\n",
    "\n",
    "    # If key exists, append the data. Otherwise, store this df in dictionary.\n",
    "    if key_thresh in df_dict_thresh:\n",
    "        df_dict_thresh[key_thresh] = pd.concat([df_dict_thresh[key_thresh], df], ignore_index=True)\n",
    "    else:\n",
    "        df_dict_thresh[key_thresh] = df\n",
    "\n",
    "    # Change the index for dataframes where process_type == 'trash'\n",
    "    if process_type == 'split' and \"index\" in df.columns:\n",
    "        df['group'] = df['index'].str.split('-').str[2]\n",
    "        group = df['group'].iloc[0]\n",
    "\n",
    "    key_split = (id_file, thresh_file, process_type, group)\n",
    "\n",
    "    if key_split in df_dict_split:\n",
    "        df_dict_split[key_split] = pd.concat([df_dict_split[key_split], df], ignore_index=True)\n",
    "    else:\n",
    "        df_dict_split[key_split] = df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "thresholds = [0, 0.001, 0.01, 0.1, 1]\n",
    "columns = df.columns[2:6]  # update this to match your data\n",
    "ylabel = ['Jaccard-index', 'Bray–Curtis', 'l1-score', 'l2-score']\n",
    "\n",
    "# Loop over each threshold\n",
    "for threshold in thresholds:\n",
    "    # Loop over each column\n",
    "    for i, column in enumerate(columns):\n",
    "        # Initialize figure and axes for each plot\n",
    "        fig, ax = plt.subplots(figsize=(16,9))\n",
    "\n",
    "        new_array = np.array(np.append(df['index'].values[::], [\"200M\",\"300M\"]))\n",
    "\n",
    "        for key, df in df_dict_thresh.items():\n",
    "            if (df[\"process_type\"] == 'trash').any() and (df[\"thresh_file\"] == str(threshold)).any():\n",
    "                ax.plot(df['index'], df[column], label=key[0], marker='o')\n",
    "\n",
    "        # Set xticks with labels\n",
    "        ax.set_xticks(range(len(new_array)))  # Set xticks as range of new_array length\n",
    "        ax.set_xticklabels(new_array, rotation=0)  # Set xtick labels as 'new_array' values\n",
    "\n",
    "        # Set plot title, x-axis and y-axis labels\n",
    "        ax.set_title(f'{ylabel[i]} for {threshold}% threshold')\n",
    "        ax.set_xlabel('Index')\n",
    "        ax.set_ylabel(ylabel[i])\n",
    "\n",
    "        # Add a legend to the plot\n",
    "        ax.legend()\n",
    "\n",
    "        # Display the plot\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "thresholds = [0, 0.001, 0.01, 0.1, 1]\n",
    "columns = ['jaccard_scores', 'Dissimilarity', 'l1_score', 'l2_score']\n",
    "ylabel = ['Jaccard-index', 'Bray–Curtis', 'l1-score', 'l2-score']\n",
    "\n",
    "# Loop over each threshold\n",
    "for threshold in thresholds:\n",
    "    # Loop over each column\n",
    "    for i, column in enumerate(columns):\n",
    "        # Initialize figure and axes for each plot\n",
    "        fig, ax = plt.subplots(figsize=(16,9))\n",
    "\n",
    "        # List to store data for boxplot and corresponding labels\n",
    "        data_to_plot = []\n",
    "        labels = []\n",
    "\n",
    "        # Loop over each key, dataframe in df_dict_split dictionary\n",
    "        for key, df_split in df_dict_thresh.items():\n",
    "            if (df_split[\"process_type\"] == 'split').any() and (df_split[\"thresh_file\"] == str(threshold)).any():\n",
    "                # Add df[column] data and corresponding label to the lists\n",
    "                data_to_plot.append(df_split[column].values)\n",
    "                labels.append(', '.join(map(str, list(set(df_split.index)))))\n",
    "\n",
    "        # Plot boxplot for data_to_plot\n",
    "        sns.boxplot(data=data_to_plot, ax=ax)\n",
    "\n",
    "        # Set plot title, x-axis and y-axis labels\n",
    "        ax.set_xticklabels(labels, rotation=45)\n",
    "        ax.set_title(f'{ylabel[i]} for {threshold}% threshold')\n",
    "        ax.set_xlabel('id_file')\n",
    "        ax.set_ylabel(ylabel[i])\n",
    "\n",
    "        # Display the plot\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "thresholds = [0, 0.001, 0.01, 0.1, 1]\n",
    "columns = ['jaccard_scores', 'Dissimilarity', 'l1_score', 'l2_score']\n",
    "ylabel = ['Jaccard-index', 'Bray–Curtis', 'l1-score', 'l2-score']\n",
    "\n",
    "# Loop over each threshold\n",
    "for threshold in thresholds:\n",
    "    # Loop over each column\n",
    "    for i, column in enumerate(columns):\n",
    "        # Loop over each key, dataframe in df_dict_split dictionary\n",
    "        for key, df_split in df_dict_thresh.items():\n",
    "            if (df_split[\"process_type\"] == 'split').any() and (df_split[\"thresh_file\"] == str(threshold)).any():\n",
    "                # Initialize figure and axes for each plot\n",
    "                fig, ax = plt.subplots(figsize=(16,9))\n",
    "                # print(df_split.index.unique())\n",
    "                # Plot boxplot for df_split[column] with 'group' column as x-axis\n",
    "                sns.boxplot(x='group', y=column, data=df_split, ax=ax)\n",
    "\n",
    "                # Set plot title, x-axis and y-axis labels\n",
    "                ax.set_title(f'{df_split.index.unique()[0]} - {ylabel[i]} for {threshold}% threshold')\n",
    "                ax.set_xlabel('Group')\n",
    "                ax.set_ylabel(ylabel[i])\n",
    "\n",
    "                # Display the plot\n",
    "                plt.tight_layout()\n",
    "                plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a dictionary to hold dictionaries for each threshold\n",
    "threshold_dfs = {threshold: {} for threshold in thresholds}\n",
    "\n",
    "# Loop over each threshold\n",
    "for threshold in thresholds:\n",
    "    # Loop over each key, dataframe in df_dict_split dictionary\n",
    "    for key, df in df_dict_thresh.items():\n",
    "        if (df[\"thresh_file\"] == str(threshold)).any():\n",
    "            df.loc[df['Dissimilarity'] <= 0.01, 't_Dissimilarity'] = 1\n",
    "            df.loc[df['Dissimilarity'] > 0.01, 't_Dissimilarity'] = 0\n",
    "\n",
    "            if df[\"process_type\"].str.contains('split').any():\n",
    "                df['group'] = df['group'].apply(lambda x: str(int(x.split('M')[0]) * 10) + 'M')\n",
    "                df.loc[df['jaccard_scores'] <= 0.95, 't_jaccard_scores'] = 1\n",
    "                df.loc[df['jaccard_scores'] > 0.95, 't_jaccard_scores'] = 0\n",
    "            elif df[\"process_type\"].str.contains('trash').any():\n",
    "                df.rename(columns={'index':'group'}, inplace=True)\n",
    "                df.loc[df['Ground_truth'] <= 0.95, 't_jaccard_scores'] = 1\n",
    "                df.loc[df['Ground_truth'] > 0.95, 't_jaccard_scores'] = 0\n",
    "\n",
    "            df = df[['group', 't_Dissimilarity', 't_jaccard_scores']]\n",
    "\n",
    "            # Add the modified dataframe to the relevant dictionary\n",
    "            threshold_dfs[threshold][key] = df\n",
    "\n",
    "    # Sort dictionaries by key within threshold_dfs\n",
    "    threshold_dfs[threshold] = {k: threshold_dfs[threshold][k] for k in sorted(threshold_dfs[threshold])}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Prepare the label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Define a dictionary to store predictions for each threshold\n",
    "predictions = {}\n",
    "\n",
    "# Iterate over each threshold\n",
    "for threshold in thresholds:\n",
    "    # Define the model\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    # Get the dataframes for this threshold\n",
    "    threshold_dict = threshold_dfs[threshold]\n",
    "\n",
    "    # Select the first 10 dataframes\n",
    "    dfs_to_train = [df for key, df in sorted(threshold_dict.items())[:10]]\n",
    "\n",
    "    # Concatenate the dataframes into one\n",
    "    train_data = pd.concat(dfs_to_train)\n",
    "\n",
    "    # Separate features and target\n",
    "    X = train_data[['t_Dissimilarity', 't_jaccard_scores']]\n",
    "    y = le.fit_transform(train_data['group'])\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Make a prediction for a single value\n",
    "    single_value_to_predict = [[0.05, 0.95]]  # replace with your data\n",
    "    prediction = model.predict(single_value_to_predict)\n",
    "\n",
    "    # Convert the predicted label back to original label\n",
    "    predicted_label = le.inverse_transform(prediction)\n",
    "\n",
    "    # Store prediction for this threshold\n",
    "    predictions[threshold] = predicted_label\n",
    "\n",
    "# Print all predictions\n",
    "print(predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "        self.output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Iterate over each threshold\n",
    "for threshold in thresholds:\n",
    "    model = MyModel()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    threshold_dict = threshold_dfs[threshold]\n",
    "\n",
    "    dfs_to_train = [df for key, df in sorted(threshold_dict.items())[:10]]\n",
    "\n",
    "    train_data = pd.concat(dfs_to_train)\n",
    "\n",
    "    X = torch.Tensor(train_data[['t_Dissimilarity', 't_jaccard_scores']].values)\n",
    "    y = torch.Tensor(le.fit_transform(train_data['group'])).reshape(-1, 1)\n",
    "\n",
    "    dataset = TensorDataset(X, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "    for epoch in range(150):\n",
    "        for inputs, targets in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    single_value_to_predict = torch.Tensor([[0.05, 0.9]])\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        prediction = model(single_value_to_predict)\n",
    "    predicted_label = le.inverse_transform([round(prediction.item())])\n",
    "\n",
    "    results[threshold] = predicted_label\n",
    "\n",
    "print(results)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
